{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to automatically make diacritical corrections in Hebrew text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defines letters and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "aleph_bet = ['א','ב','ג','ד','ה','ו','ז','ח','ט','י','כ','ך','ל','מ','ם',\n",
    "             'נ','ן','ס','ע','פ','ף','צ','ק','ר','ש','ת','װ','ױ','ײ','יִ',\n",
    "             'ﬡ','ﬢ','ﬣ','ﬤ','ﬥ','ﬦ','ﬧ','ﬨ','שׁ','שׂ','שּׁ','שּׂ','אַ','אָ',\n",
    "             'גּ','דּ','הּ','וּ','זּ','טּ','יּ','ךּ','כּ','לּ','מּ','נּ','סּ','ףּ',\n",
    "             'פּ','צּ','שּ','תּ','וֹ','בֿ','כֿ','פֿ','ﭏ','בּ', 'קּ']\n",
    "\n",
    "cant = ['֑','֒','֓','֔','֕','֖','֗','֘','֙','֚','֛','֜',\n",
    "             '֝','֞','֠','֡','֢','֣','֤','֥','֦','֧','֨','֩','֪','֫','֬','֭','֯','׃']\n",
    "\n",
    "vowel = ['ְ','ֱ','ֲ','ֳ','ִ','ֵ','ֶ','ַ','ָ','ֹ','ֺ','ֻ','ּ','ֽ','־','ֿ','ׁ','ׂ','ׄ','ׅ','ׇ']\n",
    "\n",
    "letter_with_dagesh = ['שּׁ','שּׂ','גּ','דּ','זּ','טּ','יּ','כּ','לּ','מּ','נּ','סּ','פּ','צּ','שּ','תּ','בּ','קּ']\n",
    "rafe = 'ֿ'\n",
    "shva = vowel[0]\n",
    "chataf_vowels = vowel[1:4]\n",
    "short_vowels = [vowel[4],vowel[6],vowel[7],vowel[11],vowel[20]]\n",
    "long_vowels = ['וֹ','וּ', vowel[5], vowel[8], aleph_bet[9], 'ֹ']\n",
    "vowels_limited = vowel[0:4]+short_vowels+long_vowels\n",
    "dagesh = 'ּ'\n",
    "maqqaf = '־'\n",
    "\n",
    "gutterals = ['א','ה','ח','ע','ר' ,'ﬡ','ﬣ','ﬧ']             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "shem = 'יהוה'\n",
    "shem_vowels = 'יְהֹוָה'\n",
    "yy_vowels = aleph_bet[9]+vowel[0]+aleph_bet[9]+vowel[8]\n",
    "\n",
    "kal = aleph_bet[52] + vowel[8] + aleph_bet[12]\n",
    "khal = aleph_bet[10] + vowel[8] + aleph_bet[12]\n",
    "kol_maqqaf = aleph_bet[52] + vowel[20] + aleph_bet[12] + '־'\n",
    "khol_maqqaf = aleph_bet[10] + vowel[20] + aleph_bet[12] + '־'\n",
    "kol_space = aleph_bet[52] + vowel[20] + aleph_bet[12] + ' '\n",
    "khol_space = aleph_bet[10] + vowel[20] + aleph_bet[12] + ' '\n",
    "\n",
    "et = 'אֶת'\n",
    "ve_et = 'וְאֶת'\n",
    "space_et_space = ' ' + 'אֶת' + ' '\n",
    "space_ve_et_space = ' ' + 'וְאֶת' + ' '\n",
    "et_maqqaf = ' ' + 'אֶת' + '־'\n",
    "ve_et_maqqaf = ' ' + 'וְאֶת' + '־'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "shva_exceptions = ['שְׁתֵּי','שְׁתָּיִם','שְׁתַּיִם','שְׁנִַים','שְׁנֵי','שְׁתֵּים','שְׁנֵים']\n",
    "battim = 'בָּתִּים'\n",
    "vattim = 'בָתִּים'\n",
    "ana = 'אָנָּא'\n",
    "anah = 'אָנָּה'\n",
    "kamatz_katan_exceptions = [battim, vattim, ana, anah]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the shem converter \"eats\" some special characters next to sheimot, this stops it from doing that\n",
    "special_characters = ['{', '}','\\\\',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strips vowels and cantelation marks from words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes trop and vowels\n",
    "def nonalpha_remover(word):\n",
    "    no_cant_word = ''\n",
    "    for letter in word:\n",
    "        if letter.isalpha() == True:\n",
    "            no_cant_word = no_cant_word + letter\n",
    "    return no_cant_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes trop but not vowels\n",
    "def trop_remover(word):\n",
    "    no_cant_word = ''\n",
    "    for letter in word:\n",
    "        if letter not in cant:\n",
    "            no_cant_word = no_cant_word + letter\n",
    "    return no_cant_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converts Shem-Havaya to double-yud while preserving cantelation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shem_converter(word):\n",
    "    prefix = ''\n",
    "    if word[0] != aleph_bet[9]:\n",
    "        prefix = prefix + word[0]\n",
    "        i = 1\n",
    "        if word[1].isalpha() == False:\n",
    "            prefix = prefix + word[1]\n",
    "            if word[2].isalpha() == False:\n",
    "                prefix = prefix + word[2]\n",
    "    no_prefix_word = word[len(prefix):]\n",
    "\n",
    "    if len(prefix) > 0:\n",
    "        yud1 = aleph_bet[9]\n",
    "    else:\n",
    "        yud1 = aleph_bet[9]+vowel[0]\n",
    "\n",
    "    yud2 = aleph_bet[9]+vowel[8]\n",
    "\n",
    "    cant_marks = []\n",
    "\n",
    "    #finds suffix\n",
    "    suffix = ''\n",
    "    i = -1\n",
    "    while word[i] != aleph_bet[4]:\n",
    "        if word[i] in special_characters:\n",
    "            suffix = word[i] + suffix\n",
    "        i = i-1\n",
    "    \n",
    "    for character in no_prefix_word:\n",
    "        if character in cant:\n",
    "            cant_marks.append(character)\n",
    "    if len(cant_marks) == 0:\n",
    "        new_shem = prefix + yud1 + yud2 + suffix\n",
    "    elif len(cant_marks) == 1:\n",
    "        new_shem = prefix + yud1 + yud2 + cant_marks[0] + suffix\n",
    "    elif len(cant_marks) == 2:\n",
    "        new_shem = prefix + yud1 + cant_marks[0] + yud2 + cant_marks[1] + suffix\n",
    "\n",
    "    return new_shem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creates new paragraph with double-yud in place of Shem Havaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this needs to be fixed to stop eating special characters (i.e. brackets, \\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_shem(paragraph):\n",
    "    paragraph = str.replace(paragraph, '־', ' ־ ')\n",
    "    par_list = paragraph.split()\n",
    "    for word in par_list:\n",
    "        index = par_list.index(word)\n",
    "        if shem in nonalpha_remover(word):\n",
    "            double_yud = shem_converter(word)\n",
    "            par_list[index] = double_yud\n",
    "\n",
    "    new_par = ' '.join(par_list)\n",
    "    new_par = str.replace(new_par, ' ־ ','־')\n",
    "    new_par = str.replace(new_par, '׃', '׃')\n",
    "    return new_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use https://he.wikisource.org/wiki/%D7%9E%D7%A7%D7%A8%D7%90 for testing texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puts a kamatz katan and maqqaf in \"kol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script does not work on words with trope\n",
    "#Since pesukim from wikisource have maqqafs and kamatz katans, it shouldn't make it less useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kamatz_exception(word):\n",
    "    if word[-1] != aleph_bet[12]:\n",
    "        return True\n",
    "    elif aleph_bet[9] in word:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    #returns \"true\" if the word is a likely false positive for the word \"kol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kol_kamatz_katan(paragraph):\n",
    "    paragraph = str.replace(paragraph, '־', ' ־ ')\n",
    "    par_list = paragraph.split()\n",
    "    #Paragraph is now split into words\n",
    "    for word in par_list:\n",
    "        index = par_list.index(word)\n",
    "        if (kal in word or khal in word) and kamatz_exception(word) == False:\n",
    "            split_word = word.split(vowel[8])\n",
    "            word = vowel[20].join(split_word)\n",
    "            par_list[index] = word\n",
    "            #If \"k(h)al\" appears in a word, change it to a kamatz katan\n",
    "    new_par = ' '.join(par_list)\n",
    "    new_par = str.replace(new_par, ' ־ ','־')\n",
    "    #Put paragraph back together\n",
    "    if kol_space in new_par: \n",
    "        new_par_split = new_par.split(kol_space)\n",
    "        new_par = kol_maqqaf.join(new_par_split)\n",
    "    if khol_space in new_par:\n",
    "        new_par_split = new_par.split(khol_space)\n",
    "        new_par = khol_maqqaf.join(new_par_split)\n",
    "    #Previous if-statements swap a space following \"kol\" to a maqqaf\n",
    "    new_par = str.replace(new_par, '׃', '׃')\n",
    "    return new_par"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puts a Maqqaf after \"et\" (when it has a segol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script does not work on words with trope\n",
    "#Since pesukim from wikisource have maqqafs, this shouldn't be a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def et_fixer(paragraph):\n",
    "    par_list = paragraph.split()\n",
    "    if et in par_list:\n",
    "        new_par_split = paragraph.split(space_et_space)\n",
    "        new_paragraph = et_maqqaf.join(new_par_split)\n",
    "        new_par_split = new_paragraph.split(space_ve_et_space)\n",
    "        new_paragraph = ve_et_maqqaf.join(new_par_split)\n",
    "    else:\n",
    "        new_paragraph = paragraph\n",
    "    return new_paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puts a kamatz katan in common kamatz-katan words and situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script does not work on words with trope\n",
    "#Since pesukim from wikisource have kamatz katans, this shouldn't be too much of a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "chakhma = 'חָכְמָה'\n",
    "chokhma = 'חׇכְמָה'\n",
    "karban = 'קָרְבַּן'\n",
    "korban = 'קׇרְבַּן'\n",
    "kareinu = 'קָרְאֵֽנוּ'\n",
    "koreinu = 'קׇרְאֵֽנוּ'\n",
    "karbe_ = 'קָרְבְּ'\n",
    "korbe_ = 'קׇרְבְּ'\n",
    "kadshe_ = 'קָדְשְׁ'\n",
    "kodshe_ = 'קׇדְשְׁ'\n",
    "kadashim = 'קׇדָשִׁים'\n",
    "kodashim = 'קׇדָשִׁים'\n",
    "\n",
    "words_to_fix = [chakhma, karban, kareinu, karbe_, kadshe_, kadashim]\n",
    "corrected_words = [chokhma, korban, koreinu, korbe_, kodshe_, kodashim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kamatz_katan_adder(word):    \n",
    "    #prevents script from erroneously fixing false positives\n",
    "    nt_word = trop_remover(word)\n",
    "\n",
    "    for index in range(0,len(kamatz_katan_exceptions)):\n",
    "        if kamatz_katan_exceptions[index] in nt_word:\n",
    "            return word\n",
    "    \n",
    "    for index in range(1,len(word)-2):\n",
    "        if word[index] == vowel[8]:\n",
    "            i = index\n",
    "            while word[i] not in aleph_bet:\n",
    "                i = i+1\n",
    "                if i>len(word)-1:\n",
    "                    break\n",
    "            if i<len(word)-1:\n",
    "                next_consonant = word[i]\n",
    "                if next_consonant in letter_with_dagesh:\n",
    "                    word = word[:index]+vowel[20]+word[index:]\n",
    "            \n",
    "            i = index+1\n",
    "            while word[i] not in vowels_limited:\n",
    "                i = i+1\n",
    "                if i>len(word)-1:\n",
    "                    return word\n",
    "            next_vowel = word[i]\n",
    "            if next_vowel == chataf_vowels[2] and next_consonant in gutterals:\n",
    "                word = word[:index]+vowel[20]+word[index:]\n",
    "    \n",
    "    #add kamatz katan if next vowel is chataf-kamatz and the next consonant is a gutteral\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kamatz_katan(paragraph):\n",
    "    #This goes through the list of common words with kamatz katan (besides \"kol\")\n",
    "    #and corrects them if they are present.\n",
    "    #This list can be added to as needed.\n",
    "    for index in range(len(words_to_fix)):\n",
    "        paragraph = paragraph.replace(words_to_fix[index],corrected_words[index])\n",
    "    par_list = paragraph.split()\n",
    "    \n",
    "    #Calls the kamatz_katan_adder for each word in paragraph, if that word has a kamatz at all\n",
    "    for index in range(len(par_list)-1):\n",
    "        if vowel[8] in par_list[index]:\n",
    "            par_list[index] = kamatz_katan_adder(par_list[index])\n",
    "    paragraph = ' '.join(par_list)\n",
    "    return paragraph  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marks shva na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserts a rafe to mark a shva na'\n",
    "def na_marker(paragraph,index):\n",
    "    if paragraph[index-1] == rafe or paragraph[index+1] == rafe:\n",
    "        return paragraph\n",
    "        #does nothing, if the shva is already marked with a rafe\n",
    "    else:\n",
    "        par_start = paragraph[:index]\n",
    "        par_end = paragraph[index:]\n",
    "        new_par = par_start+rafe+par_end\n",
    "        return new_par\n",
    "        #adds a rafe over the input letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determines what shvas are na' in a word, and calls the program to mark them\n",
    "def shva_na_function(word):\n",
    "    nt_word = trop_remover(word)\n",
    "    #this skips instances of shem hashem\n",
    "    if shem_vowels in nt_word or yy_vowels in nt_word:\n",
    "        return word\n",
    "    if nt_word in shva_exceptions:\n",
    "        return word\n",
    "    for index in range(1,len(word)-2):\n",
    "        i = index\n",
    "        if word[index] != shva:\n",
    "            continue\n",
    "            #this doesn't bother with the loop if the letter isn't a shva\n",
    "            \n",
    "        while word[i] not in aleph_bet:\n",
    "            i = i-1\n",
    "        previous_consonant = word[i]\n",
    "        #if the previous consonant is the beginning of the word, the shva is na'\n",
    "        if i == 0:\n",
    "            word = na_marker(word,index)\n",
    "            continue\n",
    "        if word[i-1] == maqqaf:\n",
    "            word = na_marker(word,index)\n",
    "        #if the previous consonant has a dagesh, the shva must be na'\n",
    "        if previous_consonant in letter_with_dagesh:\n",
    "            word = na_marker(word,index)\n",
    "            continue\n",
    "        if word[i+1] == dagesh or word[index+1] == dagesh:\n",
    "            word = na_marker(word,index)\n",
    "\n",
    "        #determines the previous vowel\n",
    "        i = index-2\n",
    "        while word[i] not in vowels_limited and i>0:\n",
    "            i = i-1\n",
    "        if i == 0:\n",
    "            return word\n",
    "        else:\n",
    "            previous_vowel = word[i]\n",
    "            #if the previous vowel is a shva, the current shva is na'\n",
    "            if previous_vowel == shva:\n",
    "                word = na_marker(word,index)\n",
    "            if previous_vowel in long_vowels:\n",
    "                word = na_marker(word,index)    \n",
    "        \n",
    "        #a shva following a long vowel is na', unless the long vowel is word-initial shuruk\n",
    "   \n",
    "\n",
    "    #add a way to deal with maqqaf\n",
    "    #determine how to mark סקינמלוי letters\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calls the shva_na_function for each word in the input paragraph\n",
    "def shva_na_converter(paragraph):\n",
    "    par_list = paragraph.split()\n",
    "    for word in par_list:\n",
    "        index = par_list.index(word)\n",
    "        par_list[index] = shva_na_function(word)\n",
    "    new_par = ' '.join(par_list)\n",
    "    return new_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ברוך is erroneously marked, add exception for shva that ends a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'וָלַֽיְלָה'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'וָלַֽיְלָה'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shva_na_converter(test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs Paragraph through all converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_converter(paragraph):\n",
    "    #Comment out components of the script you don't want to run\n",
    "    paragraph = convert_shem(paragraph)\n",
    "    paragraph = kol_kamatz_katan(paragraph)\n",
    "    paragraph = et_fixer(paragraph)\n",
    "    paragraph = kamatz_katan(paragraph)\n",
    "    paragraph = shva_na_converter(paragraph)\n",
    "    return paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading file from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'weekday_siddur.tex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "    lines = list(infile.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lines = []\n",
    "for line in lines:\n",
    "    new_lines.append(text_converter(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'weekday_siddur_converted.tex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    for line in new_lines:\n",
    "        if line != '':\n",
    "            if line[-1] != '\\n':\n",
    "                outfile.write(line + '\\n')\n",
    "            else:\n",
    "                outfile.write(line)\n",
    "        else:\n",
    "            outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
