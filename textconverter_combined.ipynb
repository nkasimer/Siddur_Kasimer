{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to automatically make diacritical corrections in Hebrew text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defines letters and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "aleph_bet = ['א','ב','ג','ד','ה','ו','ז','ח','ט','י','כ','ך','ל','מ','ם',\n",
    "             'נ','ן','ס','ע','פ','ף','צ','ק','ר','ש','ת','װ','ױ','ײ','יִ',\n",
    "             'ﬡ','ﬢ','ﬣ','ﬤ','ﬥ','ﬦ','ﬧ','ﬨ','שׁ','שׂ','שּׁ','שּׂ','אַ','אָ',\n",
    "             'גּ','דּ','הּ','וּ','זּ','טּ','יּ','ךּ','כּ','לּ','מּ','נּ','סּ','ףּ',\n",
    "             'פּ','צּ','שּ','תּ','וֹ','בֿ','כֿ','פֿ','ﭏ','בּ', 'קּ']\n",
    "\n",
    "cant = ['֑','֒','֓','֔','֕','֖','֗','֘','֙','֚','֛','֜',\n",
    "             '֝','֞','֠','֡','֢','֣','֤','֥','֦','֧','֨','֩','֪','֫','֬','֭','֯','׃']\n",
    "\n",
    "vowel = ['ְ','ֱ','ֲ','ֳ','ִ','ֵ','ֶ','ַ','ָ','ֹ','ֺ','ֻ','ּ','ֽ','־','ֿ','ׁ','ׂ','ׄ','ׅ','ׇ']\n",
    "\n",
    "letter_with_dagesh = ['שּׁ','שּׂ','גּ','דּ','זּ','טּ','יּ','כּ','לּ','מּ','נּ','סּ','פּ','צּ','שּ','תּ','בּ','קּ']\n",
    "rafe = 'ֿ'\n",
    "shva = vowel[0]\n",
    "chataf_vowels = vowel[1:4]\n",
    "short_vowels = [vowel[4],vowel[6],vowel[7],vowel[11],vowel[20]]\n",
    "long_vowels = ['וֹ','וּ', vowel[5], vowel[8], aleph_bet[9], 'ֹ']\n",
    "vowels_limited = vowel[0:4]+short_vowels+long_vowels\n",
    "dagesh = 'ּ'\n",
    "maqqaf = '־'\n",
    "meteg = 'ֽ'\n",
    "dot = '֯'\n",
    "\n",
    "gutterals = ['א','ה','ח','ע','ר' ,'ﬡ','ﬣ','ﬧ']             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "shem = 'יהוה'\n",
    "shem_vowels = 'יְהֹוָה'\n",
    "yy_vowels = aleph_bet[9]+vowel[0]+aleph_bet[9]+vowel[8]\n",
    "\n",
    "kal = aleph_bet[52] + vowel[8] + aleph_bet[12]\n",
    "khal = aleph_bet[10] + vowel[8] + aleph_bet[12]\n",
    "kol_maqqaf = aleph_bet[52] + vowel[20] + aleph_bet[12] + '־'\n",
    "khol_maqqaf = aleph_bet[10] + vowel[20] + aleph_bet[12] + '־'\n",
    "kol_space = aleph_bet[52] + vowel[20] + aleph_bet[12] + ' '\n",
    "khol_space = aleph_bet[10] + vowel[20] + aleph_bet[12] + ' '\n",
    "\n",
    "et = 'אֶת'\n",
    "ve_et = 'וְאֶת'\n",
    "space_et_space = ' ' + 'אֶת' + ' '\n",
    "space_ve_et_space = ' ' + 'וְאֶת' + ' '\n",
    "et_maqqaf = ' ' + 'אֶת' + '־'\n",
    "ve_et_maqqaf = ' ' + 'וְאֶת' + '־'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "shva_exceptions = ['שְׁתֵּי','שְׁתָּיִם','שְׁתַּיִם','שְׁנִַים','שְׁנֵי','שְׁתֵּים','שְׁנֵים']\n",
    "battim = 'בָּתִּים'\n",
    "vattim = 'בָתִּים'\n",
    "ana = 'אָנָּא'\n",
    "anah = 'אָנָּה'\n",
    "kamatz_katan_exceptions = [battim, vattim, ana, anah]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the shem converter \"eats\" some special characters next to sheimot, this stops it from doing that\n",
    "special_characters = ['{', '}','\\\\',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strips vowels and cantelation marks from words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes trop and vowels\n",
    "def nonalpha_remover(word):\n",
    "    no_cant_word = ''\n",
    "    for letter in word:\n",
    "        if letter.isalpha() == True:\n",
    "            no_cant_word = no_cant_word + letter\n",
    "    return no_cant_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes trop but not vowels\n",
    "def trop_remover(word):\n",
    "    no_cant_word = ''\n",
    "    for letter in word:\n",
    "        if letter not in cant:\n",
    "            no_cant_word = no_cant_word + letter\n",
    "    return no_cant_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converts Shem-Havaya to double-yud while preserving cantelation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shem_converter(word):\n",
    "    prefix = ''\n",
    "    if word[0] != aleph_bet[9]:\n",
    "        prefix = prefix + word[0]\n",
    "        i = 1\n",
    "        if word[1].isalpha() == False:\n",
    "            prefix = prefix + word[1]\n",
    "            if word[2].isalpha() == False:\n",
    "                prefix = prefix + word[2]\n",
    "    no_prefix_word = word[len(prefix):]\n",
    "\n",
    "    if len(prefix) > 0:\n",
    "        yud1 = aleph_bet[9]\n",
    "    else:\n",
    "        yud1 = aleph_bet[9]+vowel[0]\n",
    "\n",
    "    yud2 = aleph_bet[9]+vowel[8]\n",
    "\n",
    "    cant_marks = []\n",
    "\n",
    "    #finds suffix\n",
    "    suffix = ''\n",
    "    i = -1\n",
    "    while word[i] != aleph_bet[4]:\n",
    "        if word[i] in special_characters:\n",
    "            suffix = word[i] + suffix\n",
    "        i = i-1\n",
    "    \n",
    "    for character in no_prefix_word:\n",
    "        if character in cant:\n",
    "            cant_marks.append(character)\n",
    "    if len(cant_marks) == 0:\n",
    "        new_shem = prefix + yud1 + yud2 + suffix\n",
    "    elif len(cant_marks) == 1:\n",
    "        new_shem = prefix + yud1 + yud2 + cant_marks[0] + suffix\n",
    "    elif len(cant_marks) == 2:\n",
    "        new_shem = prefix + yud1 + cant_marks[0] + yud2 + cant_marks[1] + suffix\n",
    "\n",
    "    return new_shem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creates new paragraph with double-yud in place of Shem Havaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this needs to be fixed to stop eating special characters (i.e. brackets, \\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_shem(paragraph):\n",
    "    paragraph = str.replace(paragraph, '־', ' ־ ')\n",
    "    par_list = paragraph.split()\n",
    "    for word in par_list:\n",
    "        index = par_list.index(word)\n",
    "        if shem in nonalpha_remover(word):\n",
    "            double_yud = shem_converter(word)\n",
    "            par_list[index] = double_yud\n",
    "\n",
    "    new_par = ' '.join(par_list)\n",
    "    new_par = str.replace(new_par, ' ־ ','־')\n",
    "    new_par = str.replace(new_par, '׃', '׃')\n",
    "    return new_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use https://he.wikisource.org/wiki/%D7%9E%D7%A7%D7%A8%D7%90 for testing texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puts a kamatz katan and maqqaf in \"kol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script does not work on words with trope\n",
    "#Since pesukim from wikisource have maqqafs and kamatz katans, it shouldn't make it less useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kamatz_exception(word):\n",
    "    if word[-1] != aleph_bet[12]:\n",
    "        return True\n",
    "    elif aleph_bet[9] in word:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    #returns \"true\" if the word is a likely false positive for the word \"kol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kol_kamatz_katan(paragraph):\n",
    "    paragraph = str.replace(paragraph, '־', ' ־ ')\n",
    "    par_list = paragraph.split()\n",
    "    #Paragraph is now split into words\n",
    "    for word in par_list:\n",
    "        index = par_list.index(word)\n",
    "        if (kal in word or khal in word) and kamatz_exception(word) == False:\n",
    "            split_word = word.split(vowel[8])\n",
    "            word = vowel[20].join(split_word)\n",
    "            par_list[index] = word\n",
    "            #If \"k(h)al\" appears in a word, change it to a kamatz katan\n",
    "    new_par = ' '.join(par_list)\n",
    "    new_par = str.replace(new_par, ' ־ ','־')\n",
    "    #Put paragraph back together\n",
    "    if kol_space in new_par: \n",
    "        new_par_split = new_par.split(kol_space)\n",
    "        new_par = kol_maqqaf.join(new_par_split)\n",
    "    if khol_space in new_par:\n",
    "        new_par_split = new_par.split(khol_space)\n",
    "        new_par = khol_maqqaf.join(new_par_split)\n",
    "    #Previous if-statements swap a space following \"kol\" to a maqqaf\n",
    "    new_par = str.replace(new_par, '׃', '׃')\n",
    "    return new_par"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puts a Maqqaf after \"et\" (when it has a segol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script does not work on words with trope\n",
    "#Since pesukim from wikisource have maqqafs, this shouldn't be a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def et_fixer(paragraph):\n",
    "    par_list = paragraph.split()\n",
    "    if et in par_list:\n",
    "        new_par_split = paragraph.split(space_et_space)\n",
    "        new_paragraph = et_maqqaf.join(new_par_split)\n",
    "        new_par_split = new_paragraph.split(space_ve_et_space)\n",
    "        new_paragraph = ve_et_maqqaf.join(new_par_split)\n",
    "    else:\n",
    "        new_paragraph = paragraph\n",
    "    return new_paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puts a kamatz katan in common kamatz-katan words and situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script does not work on words with trope\n",
    "#Since pesukim from wikisource have kamatz katans, this shouldn't be too much of a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chakhma = 'חָכְמָה'\n",
    "chokhma = 'חׇכְמָה'\n",
    "karban = 'קָרְבַּן'\n",
    "korban = 'קׇרְבַּן'\n",
    "kareinu = 'קָרְאֵֽנוּ'\n",
    "koreinu = 'קׇרְאֵֽנוּ'\n",
    "karbe_ = 'קָרְבְּ'\n",
    "korbe_ = 'קׇרְבְּ'\n",
    "kadshe_ = 'קָדְשְׁ'\n",
    "kodshe_ = 'קׇדְשְׁ'\n",
    "kadashim = 'קׇדָשִׁים'\n",
    "kodashim = 'קׇדָשִׁים'\n",
    "\n",
    "words_to_fix = [chakhma, karban, kareinu, karbe_, kadshe_, kadashim]\n",
    "corrected_words = [chokhma, korban, koreinu, korbe_, kodshe_, kodashim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kamatz_katan_adder(word):    \n",
    "    #prevents script from erroneously fixing false positives\n",
    "    nt_word = trop_remover(word)\n",
    "    for index in range(0,len(kamatz_katan_exceptions)):\n",
    "        if kamatz_katan_exceptions[index] in nt_word:\n",
    "            return word\n",
    "    \n",
    "    for index in range(1,len(word)-2):\n",
    "        if word[index] == vowel[8]:\n",
    "            i = index\n",
    "            while word[i] not in aleph_bet:\n",
    "                i = i+1\n",
    "                if i>len(word)-1:\n",
    "                    break\n",
    "            if i<len(word)-1:\n",
    "                next_consonant = word[i]\n",
    "                if next_consonant in letter_with_dagesh:\n",
    "                    word = word[:index]+vowel[20]+word[index:]\n",
    "            \n",
    "            i = index+1\n",
    "            while word[i] not in vowels_limited:\n",
    "                i = i+1\n",
    "                if i>len(word)-1:\n",
    "                    return word\n",
    "            next_vowel = word[i]\n",
    "            if next_vowel == chataf_vowels[2] and next_consonant in gutterals:\n",
    "                word = word[:index]+vowel[20]+word[index:]\n",
    "                return word\n",
    "            #finds the vowel after the next one.  If both are shvas, the kamatz is katan.\n",
    "            if next_vowel == shva and shva in word[index+1:]:\n",
    "                if i<len(word)-1:\n",
    "                    i = i+1\n",
    "                    while i<len(word)-2 and word[i] not in vowels_limited:\n",
    "                        i = i+1\n",
    "                    sec_vowel = word[i]\n",
    "                    if sec_vowel == shva:\n",
    "                        word = word[:index]+vowel[20]+word[index:]\n",
    "\n",
    "            #if there's a kamatz under the second-to-last consonant, and a meteg earlier in the word, the kamatz is katan\n",
    "            if meteg in word and index == len(word)-2:\n",
    "                #finds index of previous consonant.  Adds kamatz katan if meteg is before that.\n",
    "                while word[i] not in aleph_bet:\n",
    "                    i = i-1\n",
    "                while i>0 and word[i] != meteg:\n",
    "                    i = i-1\n",
    "                if word[i] == meteg:\n",
    "                    word = word[:index]+vowel[20]+word[index:]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kamatz_katan(paragraph):\n",
    "    #This goes through the list of common words with kamatz katan (besides \"kol\")\n",
    "    #and corrects them if they are present.\n",
    "    #This list can be added to as needed.\n",
    "    for index in range(len(words_to_fix)):\n",
    "        paragraph = paragraph.replace(words_to_fix[index],corrected_words[index])\n",
    "    par_list = paragraph.split()\n",
    "    #Calls the kamatz_katan_adder for each word in paragraph, if that word has a kamatz at all\n",
    "    for index in range(len(par_list)-1):\n",
    "        if vowel[8] in par_list[index]:\n",
    "            par_list[index] = kamatz_katan_adder(par_list[index])\n",
    "    paragraph = ' '.join(par_list)\n",
    "    return paragraph  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'וַיְדַבֵּ֥ר יְיָ֖ אֶל־מֹשֶׁ֥ה לֵּאמֹֽר׃ קַדֶּשׁ־לִ֨י כׇל־בְּֿכ֜וֹר פֶּ֤טֶר כׇּל־רֶ֙חֶם֙ בִּבְנֵ֣י יִשְׂרָאֵ֔ל בָּאָדָ֖ם וּבַבְּֿהֵמָ֑ה לִ֖י הֽוּא׃ וַיֹּ֨אמֶר מֹשֶׁ֜ה אֶל־הָעָ֗ם זָכ֞וֹר אֶת־הַיּ֤וֹם הַזֶּה֙ אֲשֶׁ֨ר יְֿצָאתֶ֤ם מִמִּצְרַ֙יִם֙ מִבֵּ֣ית עֲבָדִ֔ים כִּ֚י בְּֿחֹ֣זֶק יָ֔ד הוֹצִ֧יא יְיָ֛ אֶתְכֶ֖ם מִזֶּ֑ה וְֿלֹ֥א יֵאָכֵ֖ל חָמֵֽץ׃ ד הַיּ֖וֹם אַתֶּ֣ם יֹצְֿאִ֑ים בְּֿחֹ֖דֶשׁ הָאָבִֽיב׃ וְֿהָיָ֣ה כִֽי־יְֿֿבִיאֲךָ֣ יְיָ֡ אֶל־אֶ֣רֶץ הַֽ֠כְּֿנַעֲנִ֠י וְֿהַחִתִּ֨י וְֿהָאֱמֹרִ֜י וְֿהַחִוִּ֣י וְֿהַיְבוּסִ֗י אֲשֶׁ֨ר נִשְׁבַּ֤ע לַאֲבֹתֶ֙יךָ֙ לָ֣תֶת לָ֔ךְ אֶ֛רֶץ זָבַ֥ת חָלָ֖ב וּדְבָ֑שׁ וְֿעָבַדְתָּ֛ אֶת־הָעֲבֹדָ֥ה הַזֹּ֖את בַּחֹ֥דֶשׁ הַזֶּֽה׃ שִׁבְעַ֥ת יָמִ֖ים תֹּאכַ֣ל מַצֹּ֑ת וּבַיּוֹם֙ הַשְּֿׁבִיעִ֔י חַ֖ג לַייָ׃ מַצּוֹת֙ יֵֽאָכֵ֔ל אֵ֖ת שִׁבְעַ֣ת הַיָּמִ֑ים וְֿלֹֽא־יֵרָאֶ֨ה לְֿךָ֜ חָמֵ֗ץ וְֿלֹֽא־יֵרָאֶ֥ה לְֿךָ֛ שְֿׂאֹ֖ר בְּֿכׇל־גְּֿבֻלֶֽךָ׃ וְֿהִגַּדְתָּ֣ לְֿבִנְךָ֔ בַּיּ֥וֹם הַה֖וּא לֵאמֹ֑ר בַּעֲב֣וּר זֶ֗ה עָשָׂ֤ה יְיָ֙ לִ֔י בְּֿצֵאתִ֖י מִמִּצְרָֽיִם׃ וְֿהָיָה֩ לְֿךָ֨ לְֿא֜וֹת עַל־יָדְֿךָ֗ וּלְזִכָּרוֹן֙ בֵּ֣ין עֵינֶ֔יךָ לְֿמַ֗עַן תִּהְיֶ֛ה תּוֹרַ֥ת יְיָ֖ בְּֿפִ֑יךָ כִּ֚י בְּֿיָ֣ד חֲזָקָ֔ה הוֹצִֽאֲךָ֥ יְיָ֖ מִמִּצְרָֽיִם׃ וְֿשָׁמַרְתָּ֛ אֶת־הַחֻקָּ֥ה הַזֹּ֖את לְֿמוֹעֲדָ֑הּ מִיָּמִ֖ים יָמִֽימָה׃\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'וַיְדַבֵּ֥ר יְיָ֖ אֶל־מֹשֶׁ֥ה לֵּאמֹֽר׃ קַדֶּשׁ־לִ֨י כׇל־בְּֿכ֜וֹר פֶּ֤טֶר כׇּל־רֶ֙חֶם֙ בִּבְנֵ֣י יִשְׂרָאֵ֔ל בָּאָדָ֖ם וּבַבְּֿהֵמָ֑ה לִ֖י הֽוּא׃ וַיֹּ֨אמֶר מֹשֶׁ֜ה אֶל־הָעָ֗ם זָכ֞וֹר אֶת־הַיּ֤וֹם הַזֶּה֙ אֲשֶׁ֨ר יְֿצָאתֶ֤ם מִמִּצְרַ֙יִם֙ מִבֵּ֣ית עֲבָדִ֔ים כִּ֚י בְּֿחֹ֣זֶק יָ֔ד הוֹצִ֧יא יְיָ֛ אֶתְכֶ֖ם מִזֶּ֑ה וְֿלֹ֥א יֵאָכֵ֖ל חָמֵֽץ׃ ד הַיּ֖וֹם אַתֶּ֣ם יֹצְֿאִ֑ים בְּֿחֹ֖דֶשׁ הָאָבִֽיב׃ וְֿהָיָ֣ה כִֽי־יְֿֿבִיאֲךָ֣ יְיָ֡ אֶל־אֶ֣רֶץ הַֽ֠כְּֿנַעֲנִ֠י וְֿהַחִתִּ֨י וְֿהָאֱמֹרִ֜י וְֿהַחִוִּ֣י וְֿהַיְבוּסִ֗י אֲשֶׁ֨ר נִשְׁבַּ֤ע לַאֲבֹתֶ֙יךָ֙ לָ֣תֶת לָ֔ךְ אֶ֛רֶץ זָבַ֥ת חָלָ֖ב וּדְבָ֑שׁ וְֿעָבַדְתָּ֛ אֶת־הָעֲבֹדָ֥ה הַזֹּ֖את בַּחֹ֥דֶשׁ הַזֶּֽה׃ שִׁבְעַ֥ת יָמִ֖ים תֹּאכַ֣ל מַצֹּ֑ת וּבַיּוֹם֙ הַשְּֿׁבִיעִ֔י חַ֖ג לַייָ׃ מַצּוֹת֙ יֵֽאָכֵ֔ל אֵ֖ת שִׁבְעַ֣ת הַיָּמִ֑ים וְֿלֹֽא־יֵרָאֶ֨ה לְֿךָ֜ חָמֵ֗ץ וְֿלֹֽא־יֵרָאֶ֥ה לְֿךָ֛ שְֿׂאֹ֖ר בְּֿכׇל־גְּֿבֻלֶֽךָ׃ וְֿהִגַּדְתָּ֣ לְֿבִנְךָ֔ בַּיּ֥וֹם הַה֖וּא לֵאמֹ֑ר בַּעֲב֣וּר זֶ֗ה עָשָׂ֤ה יְיָ֙ לִ֔י בְּֿצֵאתִ֖י מִמִּצְרָֽיִם׃ וְֿהָיָה֩ לְֿךָ֨ לְֿא֜וֹת עַל־יָדְֿךָ֗ וּלְזִכָּרוֹן֙ בֵּ֣ין עֵינֶ֔יךָ לְֿמַ֗עַן תִּהְיֶ֛ה תּוֹרַ֥ת יְיָ֖ בְּֿפִ֑יךָ כִּ֚י בְּֿיָ֣ד חֲזָקָ֔ה הוֹצִֽאֲךָ֥ יְיָ֖ מִמִּצְרָֽיִם׃ וְֿשָׁמַרְתָּ֛ אֶת־הַחֻקָּ֥ה הַזֹּ֖את לְֿמוֹעֲדָ֑הּ מִיָּמִ֖ים יָמִֽימָה׃\\\\'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kamatz_katan(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'לָ֔ךְ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ְ'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marks shva na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserts a rafe to mark a shva na'\n",
    "def na_marker(paragraph,index):\n",
    "    if paragraph[index-1] == rafe or paragraph[index+1] == rafe:\n",
    "        return paragraph\n",
    "        #does nothing, if the shva is already marked with a rafe\n",
    "    else:\n",
    "        par_start = paragraph[:index]\n",
    "        par_end = paragraph[index:]\n",
    "        new_par = par_start+rafe+par_end\n",
    "        return new_par\n",
    "        #adds a rafe over the input letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determines what shvas are na' in a word, and calls the program to mark them\n",
    "def shva_na_function(word):\n",
    "    nt_word = trop_remover(word)\n",
    "    #this skips instances of shem hashem\n",
    "    if shem_vowels in nt_word or yy_vowels in nt_word:\n",
    "        return word\n",
    "    if nt_word in shva_exceptions:\n",
    "        return word\n",
    "    for index in range(1,len(word)-2):\n",
    "        i = index\n",
    "        if word[index] != shva:\n",
    "            continue\n",
    "            #this doesn't bother with the loop if the letter isn't a shva\n",
    "            \n",
    "        while word[i] not in aleph_bet:\n",
    "            i = i-1\n",
    "        previous_consonant = word[i]\n",
    "        #if the previous consonant is the beginning of the word, the shva is na'\n",
    "        if i == 0:\n",
    "            word = na_marker(word,index)\n",
    "            continue\n",
    "        if word[i-1] == maqqaf:\n",
    "            word = na_marker(word,index)\n",
    "        #if the previous consonant has a dagesh, the shva must be na'\n",
    "        if previous_consonant in letter_with_dagesh:\n",
    "            word = na_marker(word,index)\n",
    "            continue\n",
    "        if word[i+1] == dagesh or word[index+1] == dagesh:\n",
    "            word = na_marker(word,index)\n",
    "            continue\n",
    "            \n",
    "        #determines the next consonant\n",
    "        i = index + 1\n",
    "        while word[i] not in aleph_bet and i<len(word)-1:\n",
    "            i = i+1\n",
    "        next_consonant = word[i]\n",
    "        if next_consonant == previous_consonant:\n",
    "            word = na_marker(word,index)\n",
    "            continue\n",
    "\n",
    "        #determines the previous vowel\n",
    "        i = index-2\n",
    "        while word[i] not in vowels_limited and i>0:\n",
    "            i = i-1\n",
    "        if i == 0:\n",
    "            return word\n",
    "        else:\n",
    "            previous_vowel = word[i]\n",
    "            #if the previous vowel is a shva, the current shva is na'\n",
    "            if previous_vowel == shva:\n",
    "                word = na_marker(word,index)\n",
    "            if previous_vowel in long_vowels:\n",
    "                word = na_marker(word,index)    \n",
    "        \n",
    "        #a shva following a long vowel is na', unless the long vowel is word-initial shuruk\n",
    "   \n",
    "\n",
    "    #determine how to mark סקינמלוי letters\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calls the shva_na_function for each word in the input paragraph\n",
    "def shva_na_converter(paragraph):\n",
    "    par_list = paragraph.split()\n",
    "    for word in par_list:\n",
    "        index = par_list.index(word)\n",
    "        par_list[index] = shva_na_function(word)\n",
    "    new_par = ' '.join(par_list)\n",
    "    return new_par"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes shva marking character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this program allows the changing of all rafes used to mark shva into another character\n",
    "#in this case a circle above the letter\n",
    "#this could be adapted to change a text that uses the dot to using something else\n",
    "def shva_na_mark_changer(paragraph):\n",
    "    new_paragraph = paragraph.replace(rafe,dot)\n",
    "    return new_paragraph\n",
    "    #return new_paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistake catcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Catches typographical issues lingering around in here\n",
    "def mistake_catcher(paragraph):\n",
    "    dot2 = dot + dot\n",
    "    rafe2 = rafe + rafe\n",
    "    _2kamatz1 = vowel[8] + vowel[20]\n",
    "    _2kamatz2 = vowel[20] + vowel[8]\n",
    "    while dot2 in paragraph or rafe2 in paragraph or _2kamatz1 in paragraph or _2kamatz2 in paragraph:\n",
    "        paragraph = paragraph.replace(dot2,dot)\n",
    "        paragraph = paragraph.replace(rafe2,rafe)\n",
    "        paragraph = paragraph.replace(_2kamatz1,vowel[20])\n",
    "        paragraph = paragraph.replace(_2kamatz2,vowel[20])\n",
    "    return paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'וְֿצׇׇׇהֳרָֽיִם'\n",
    "_2kamatz1 = vowel[8] + vowel[20]\n",
    "_2kamatz2 = vowel[20] + vowel[8]\n",
    "if _2kamatz1 in test:\n",
    "    print('1')\n",
    "if _2kamatz2 in test:\n",
    "    print('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'וְֿצׇׇׇהֳרָֽיִם'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fixed = test.replace(_2kamatz1,vowel[20])\n",
    "test_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = 'יְ֯֯בִאֲךָ֤'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _2kamatz2 in test or _2kamatz1 in test:\n",
    "    print('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script got here\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'יְ֯בִאֲךָ֤'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistake_catcher(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs Paragraph through all converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_converter(paragraph):\n",
    "    #Comment out components of the script you don't want to run\n",
    "    paragraph = convert_shem(paragraph)\n",
    "    #paragraph = kol_kamatz_katan(paragraph)\n",
    "    #paragraph = et_fixer(paragraph)\n",
    "    #paragraph = kamatz_katan(paragraph)\n",
    "    #paragraph = shva_na_converter(paragraph)\n",
    "    paragraph = shva_na_mark_changer(paragraph)\n",
    "    paragraph = mistake_catcher(paragraph)\n",
    "    return paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading file from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'siddur.tex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "    lines = list(infile.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lines = []\n",
    "line_number = 1\n",
    "for line in lines:\n",
    "    new_lines.append(text_converter(line))\n",
    "    #for troubleshooting--identifies the last line where the script ran\n",
    "    #print('line number', line_number, 'outputted successfully')\n",
    "    line_number = line_number+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'siddur_converted.tex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    for line in new_lines:\n",
    "        if line != '':\n",
    "            if line[-1] != '\\n':\n",
    "                outfile.write(line + '\\n')\n",
    "            else:\n",
    "                outfile.write(line)\n",
    "        else:\n",
    "            outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
